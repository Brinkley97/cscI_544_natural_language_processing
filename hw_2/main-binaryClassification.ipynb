{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2- Binary Classification \n",
    "- Detravious Jamari Brinkley\n",
    "- CSCI-544: Applied Natural Language Processing\n",
    "- python version: 3.11.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/brinkley97/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"../datasets/amazon_reviews_us_Office_Products_v1_00.tsv\"\n",
    "amazon_reviews_copy_df = pd.read_csv(dataset, sep='\\t', on_bad_lines='skip', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640254 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body\n",
       "0                 5                                     Great product.\n",
       "1                 5  What's to say about this commodity item except...\n",
       "2                 5    Haven't used yet, but I am sure I will like it.\n",
       "3                 1  Although this was labeled as &#34;new&#34; the...\n",
       "4                 4                    Gorgeous colors and easy to use\n",
       "...             ...                                                ...\n",
       "2640249           4  I can't live anymore whithout my Palm III. But...\n",
       "2640250           4  Although the Palm Pilot is thin and compact it...\n",
       "2640251           4  This book had a lot of great content without b...\n",
       "2640252           5  I am teaching a course in Excel and am using t...\n",
       "2640253           5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640254 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ratings_df = amazon_reviews_copy_df.loc[0:, ['star_rating', 'review_body']]\n",
    "reviews_ratings_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_reviews(df: pd.DataFrame, review_col_name: str, number_of_reviews: int = 3):\n",
    "    \"\"\"Include reviews and ratings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    review_col_name: `str`\n",
    "        The specific_column to get the reviews and ratings of\n",
    "    \n",
    "    number_of_reviews: `int`\n",
    "        Number of samples to include\n",
    "\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    Nothing; instead, print the reviews with ratings\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    columns_to_include = [review_col_name, 'star_rating']\n",
    "\n",
    "    # Initialize an empty list to store dictionaries\n",
    "    list_of_dicts = []\n",
    "\n",
    "    # Iterate over the specified columns and retrieve the first three rows\n",
    "    for row in df[columns_to_include].head(3).to_dict(orient='records'):\n",
    "        list_of_dicts.append({'star_rating': row['star_rating'], review_col_name: row[review_col_name]})\n",
    "\n",
    "    for dictionary in list_of_dicts:\n",
    "        print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Select 100000 reviews randomly from positive and negative classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data_type(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Update the data type of the star ratings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with rating values\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the new sentiment appened\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    valid_ratings = ['1','2','3','4','5']\n",
    "    star_rating_series = df[col_name].copy()\n",
    "\n",
    "    # Convert type to strings\n",
    "    star_rating_series.astype('str')\n",
    "\n",
    "    # Check valid list and see which of our stars match\n",
    "    rows = star_rating_series.index\n",
    "    is_rating_in_valid_ratings = rows[star_rating_series.isin(valid_ratings)]\n",
    "\n",
    "    # Convert to list\n",
    "    is_rating_in_valid_ratings = is_rating_in_valid_ratings.to_list()\n",
    "\n",
    "    updated_df = df.iloc[is_rating_in_valid_ratings]\n",
    "    updated_df[col_name] = updated_df[col_name].astype(int)\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_5812/2907883124.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  updated_df[col_name] = updated_df[col_name].astype(int)\n"
     ]
    }
   ],
   "source": [
    "updated_reviews_ratings_df = update_data_type(reviews_ratings_df, 'star_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640237 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "0                  5                                     Great product.\n",
       "1                  5  What's to say about this commodity item except...\n",
       "2                  5    Haven't used yet, but I am sure I will like it.\n",
       "3                  1  Although this was labeled as &#34;new&#34; the...\n",
       "4                  4                    Gorgeous colors and easy to use\n",
       "...              ...                                                ...\n",
       "2640249            4  I can't live anymore whithout my Palm III. But...\n",
       "2640250            4  Although the Palm Pilot is thin and compact it...\n",
       "2640251            4  This book had a lot of great content without b...\n",
       "2640252            5  I am teaching a course in Excel and am using t...\n",
       "2640253            5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640237 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_reviews_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640249</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640250</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640251</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640252</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640253</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2640080 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "0                  5                                     Great product.\n",
       "1                  5  What's to say about this commodity item except...\n",
       "2                  5    Haven't used yet, but I am sure I will like it.\n",
       "3                  1  Although this was labeled as &#34;new&#34; the...\n",
       "4                  4                    Gorgeous colors and easy to use\n",
       "...              ...                                                ...\n",
       "2640249            4  I can't live anymore whithout my Palm III. But...\n",
       "2640250            4  Although the Palm Pilot is thin and compact it...\n",
       "2640251            4  This book had a lot of great content without b...\n",
       "2640252            5  I am teaching a course in Excel and am using t...\n",
       "2640253            5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2640080 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_reviews_ratings_df = updated_reviews_ratings_df.dropna()\n",
    "updated_reviews_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         star_rating  review_body\n",
      "0              False        False\n",
      "1              False        False\n",
      "2              False        False\n",
      "3              False        False\n",
      "4              False        False\n",
      "...              ...          ...\n",
      "2640249        False        False\n",
      "2640250        False        False\n",
      "2640251        False        False\n",
      "2640252        False        False\n",
      "2640253        False        False\n",
      "\n",
      "[2640080 rows x 2 columns]\n",
      "There are no NaN values in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "nan_check = updated_reviews_ratings_df.isna()\n",
    "\n",
    "# Display the DataFrame with True where NaN values exist\n",
    "print(nan_check)\n",
    "\n",
    "# Check if any NaN value exists in the DataFrame\n",
    "if nan_check.any().any():\n",
    "    print(\"There are NaN values in the DataFrame.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# reviews per rating star_rating\n",
      "5    1582704\n",
      "4     418348\n",
      "1     306967\n",
      "3     193680\n",
      "2     138381\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"# reviews per rating\", updated_reviews_ratings_df['star_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_star_ratings(df: pd.DataFrame, col_name: str, star_value: int, number_of_reviews: int):\n",
    "    \"\"\"Build a subset balanced dataset with reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The dataframe to use\n",
    "    col_name: `str`\n",
    "        The name of the column to get reviews from\n",
    "    star_value: `int`\n",
    "        The star rating of the review\n",
    "    number_of_reviews: `int`\n",
    "        The number of sub reviews to include in sample\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    rating_df, sampled_rating_df: `tuple`\n",
    "        All reviews with that rating and the subset reviews with that rating\n",
    "    \"\"\"\n",
    "    \n",
    "    rating_df = df[df[col_name] == star_value]\n",
    "    sampled_rating_df = rating_df.sample(n=number_of_reviews)\n",
    "    return rating_df, sampled_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_reviews = 50000\n",
    "subset_reviews = 300\n",
    "\n",
    "one_star = 1\n",
    "rating_one, rating_one_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', one_star, subset_reviews)\n",
    "two_stars = 2\n",
    "rating_two, rating_two_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', two_stars, subset_reviews)\n",
    "three_stars = 3\n",
    "rating_three, rating_three_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', three_stars, subset_reviews)\n",
    "four_stars = 4\n",
    "rating_four, rating_four_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', four_stars, subset_reviews)\n",
    "five_stars = 5\n",
    "rating_five, rating_five_sampled = sample_star_ratings(updated_reviews_ratings_df, 'star_rating', five_stars, subset_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_reviews_df = pd.concat([rating_one_sampled, rating_two_sampled, rating_three_sampled, rating_four_sampled, rating_five_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1943457</th>\n",
       "      <td>1</td>\n",
       "      <td>I bought this a few months ago but just instal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030540</th>\n",
       "      <td>1</td>\n",
       "      <td>This printer may be good but after received i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843416</th>\n",
       "      <td>1</td>\n",
       "      <td>Do not buy!  Poor quality (I guess you get wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472075</th>\n",
       "      <td>1</td>\n",
       "      <td>These were a big waste of money!  I bought the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672057</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a piece of junk it worked for TWO  mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295931</th>\n",
       "      <td>5</td>\n",
       "      <td>I love the magazine binders they are good qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520672</th>\n",
       "      <td>5</td>\n",
       "      <td>Great package to use with a Canon MX700 printe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088087</th>\n",
       "      <td>5</td>\n",
       "      <td>very nice book and hard to find I hope our cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251248</th>\n",
       "      <td>5</td>\n",
       "      <td>I wanted to put in my two cents of real world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553908</th>\n",
       "      <td>5</td>\n",
       "      <td>HP has done well going back to what works.  Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "1943457            1  I bought this a few months ago but just instal...\n",
       "1030540            1  This printer may be good but after received i ...\n",
       "1843416            1  Do not buy!  Poor quality (I guess you get wha...\n",
       "472075             1  These were a big waste of money!  I bought the...\n",
       "672057             1  This is a piece of junk it worked for TWO  mon...\n",
       "...              ...                                                ...\n",
       "2295931            5  I love the magazine binders they are good qual...\n",
       "1520672            5  Great package to use with a Canon MX700 printe...\n",
       "2088087            5  very nice book and hard to find I hope our cha...\n",
       "2251248            5  I wanted to put in my two cents of real world ...\n",
       "2553908            5  HP has done well going back to what works.  Th...\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def separate_reviews_by_rating(df: pd.DataFrame, rating_col: str, threshold: int, sentiment_type: str):\n",
    "    \"\"\"Categorizes reviews by adding a rating\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    rating_col: `str`\n",
    "        Column with rating values\n",
    "    \n",
    "    threshold: `int`\n",
    "        Where to split the ratings such that categories can be formed\n",
    "\n",
    "    sentiment_type: `str`\n",
    "        One of three types of sentiment: positive, negative, or neural\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the new sentiment appened\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if sentiment_type == 'negative_review_class':\n",
    "        positive_review_threshold = df[rating_col].astype('int32') > threshold\n",
    "        df = df[positive_review_threshold]\n",
    "        df[sentiment_type] = 1\n",
    "\n",
    "    elif sentiment_type == 'neutral_review_class':\n",
    "        positive_review_threshold = df[rating_col].astype('int32') == threshold\n",
    "        df = df[positive_review_threshold]\n",
    "        df[sentiment_type] = 2\n",
    "\n",
    "    elif sentiment_type == 'positive_review_class':\n",
    "        positive_review_threshold = df[rating_col].astype('int32') < threshold\n",
    "        df = df[positive_review_threshold]\n",
    "        df[sentiment_type] = 3\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_5812/2166075515.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sentiment_type] = 1\n",
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_5812/2166075515.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sentiment_type] = 2\n",
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_5812/2166075515.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[sentiment_type] = 3\n"
     ]
    }
   ],
   "source": [
    "negative_review_class_df = separate_reviews_by_rating(sampled_reviews_df, 'star_rating', 3, 'negative_review_class')\n",
    "neutral_review_class_df = separate_reviews_by_rating(sampled_reviews_df, 'star_rating', 3, 'neutral_review_class')\n",
    "positive_review_class_df = separate_reviews_by_rating(sampled_reviews_df, 'star_rating', 3, 'positive_review_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>negative_review_class</th>\n",
       "      <th>neutral_review_class</th>\n",
       "      <th>positive_review_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1197368</th>\n",
       "      <td>4</td>\n",
       "      <td>This red \\\\\"hematite red\\\\\" has a metallic gol...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356735</th>\n",
       "      <td>4</td>\n",
       "      <td>cost to much</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123209</th>\n",
       "      <td>4</td>\n",
       "      <td>I needed separate notebooks for my many projec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213134</th>\n",
       "      <td>4</td>\n",
       "      <td>The service was good and prompt. About the glu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389143</th>\n",
       "      <td>4</td>\n",
       "      <td>When I bought this I thought for $3 bucks it w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899197</th>\n",
       "      <td>2</td>\n",
       "      <td>After four months of use, this gel wrist rest ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704072</th>\n",
       "      <td>2</td>\n",
       "      <td>No.  Very disappointing.  Should have returned.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186302</th>\n",
       "      <td>2</td>\n",
       "      <td>The unit is just as advertised, BUT it does no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174552</th>\n",
       "      <td>2</td>\n",
       "      <td>Laminated paper, like a poster.  Will probably...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126572</th>\n",
       "      <td>2</td>\n",
       "      <td>[[VIDEOID:mo3O16KXOPOQXJZ]]Running the alignme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "1197368            4  This red \\\\\"hematite red\\\\\" has a metallic gol...   \n",
       "356735             4                                       cost to much   \n",
       "2123209            4  I needed separate notebooks for my many projec...   \n",
       "213134             4  The service was good and prompt. About the glu...   \n",
       "2389143            4  When I bought this I thought for $3 bucks it w...   \n",
       "...              ...                                                ...   \n",
       "1899197            2  After four months of use, this gel wrist rest ...   \n",
       "704072             2    No.  Very disappointing.  Should have returned.   \n",
       "2186302            2  The unit is just as advertised, BUT it does no...   \n",
       "1174552            2  Laminated paper, like a poster.  Will probably...   \n",
       "2126572            2  [[VIDEOID:mo3O16KXOPOQXJZ]]Running the alignme...   \n",
       "\n",
       "         negative_review_class  neutral_review_class  positive_review_class  \n",
       "1197368                    1.0                   NaN                    NaN  \n",
       "356735                     1.0                   NaN                    NaN  \n",
       "2123209                    1.0                   NaN                    NaN  \n",
       "213134                     1.0                   NaN                    NaN  \n",
       "2389143                    1.0                   NaN                    NaN  \n",
       "...                        ...                   ...                    ...  \n",
       "1899197                    NaN                   NaN                    3.0  \n",
       "704072                     NaN                   NaN                    3.0  \n",
       "2186302                    NaN                   NaN                    3.0  \n",
       "1174552                    NaN                   NaN                    3.0  \n",
       "2126572                    NaN                   NaN                    3.0  \n",
       "\n",
       "[1500 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews_ratings_df = pd.concat([negative_review_class_df, neutral_review_class_df, positive_review_class_df])\n",
    "sampled_reviews_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_df = sampled_reviews_ratings_df['negative_review_class'].dropna()\n",
    "neutral_reviews_df = sampled_reviews_ratings_df['neutral_review_class'].dropna()\n",
    "positive_reviews_df = sampled_reviews_ratings_df['positive_review_class'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_reviews_ratings_df['binary_review_class'] = pd.concat([negative_reviews_df, positive_reviews_df])\n",
    "sampled_reviews_ratings_df['ternary_review_class'] = pd.concat([negative_reviews_df, neutral_reviews_df, positive_reviews_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., nan,  3.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_reviews_ratings_df['binary_review_class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_reviews_to_lower_case(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Convert all reviews to lower case\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the lower cased reviews\n",
    "    \"\"\"\n",
    "    \n",
    "    lower_case_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "    \n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "        # print(text_reviews_idx, type(text_review), text_review)\n",
    "\n",
    "        # NOT all reviews are strings, thus all can't be converted to lower cased\n",
    "        if type(text_review) != str:\n",
    "            print(True, text_review)\n",
    "            converted_str = str(text_review)\n",
    "            lower_case_reviews.append(text_review)\n",
    "         \n",
    "        else:\n",
    "            update_text_review = text_review.lower()\n",
    "            lower_case_reviews.append(update_text_review)\n",
    "\n",
    "    updated_df['lower_cased'] = lower_case_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_lower_cased = convert_reviews_to_lower_case(sampled_reviews_ratings_df, 'review_body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_lower_cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"reviews_lower_cased:\")\n",
    "# generate_sample_reviews(reviews_lower_cased, 'lower_cased', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove HTML and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_and_urls(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove HTML and URLs from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the html_and_urls removed\n",
    "    \"\"\"\n",
    "    \n",
    "    # url_pattern = re.compile(r'https?://\\S+|www\\. \\S+')\n",
    "\n",
    "    cleaned_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        if isinstance(text_review, str):\n",
    "            # Check and remove HTML tags\n",
    "            has_html = bool(re.search('<.*?>', text_review))\n",
    "            if has_html == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has HTML -- \", text_review)\n",
    "                pass\n",
    "\n",
    "            no_html_review = re.sub('<.*?>', ' ', text_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"without HTML -- \", no_html_review)\n",
    "        \n",
    "            # Check and remove URLs\n",
    "            has_url = bool(re.search(r'http\\S+', no_html_review))\n",
    "            if has_url == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has URL --\", no_html_review)\n",
    "                pass\n",
    "\n",
    "            no_html_url_review = re.sub(r'http\\S+', '', no_html_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"without HTML, URL -- \", no_html_url_review)\n",
    "            # print()\n",
    "            cleaned_reviews.append(no_html_url_review)\n",
    "        else:\n",
    "            # print(text_reviews_idx, text_review)\n",
    "            cleaned_reviews.append(text_review)\n",
    "            \n",
    "\n",
    "    updated_df['without_html_urls'] = cleaned_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_html_urls_df = remove_html_and_urls(reviews_lower_cased, 'lower_cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_html_urls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_html_urls:\")\n",
    "# generate_sample_reviews(no_html_urls_df, 'without_html_urls', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_contractions = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"that'll\": \"that will\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'd\": \"what would\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when'll\": \"when will\",\n",
    "    \"when'd\": \"when would\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where'll\": \"where will\",\n",
    "    \"where'd\": \"where would\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why'll\": \"why will\",\n",
    "    \"why'd\": \"why would\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how'd\": \"how would\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_and_replace_contractions(review):\n",
    "    \"\"\"Find the contractions to replace from a specific review\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    review: `str`\n",
    "        A specific review\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    non_contraction_review: `str`\n",
    "        The updated specific review with contractions expanded\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(review, str):\n",
    "        get_words = review.split()\n",
    "\n",
    "        store_non_contraction_words = []\n",
    "\n",
    "        for word in get_words:\n",
    "            if word in store_contractions:\n",
    "                non_contraction_form = store_contractions[word]\n",
    "                # print(word, \"-->\", non_contraction_form)\n",
    "\n",
    "                store_non_contraction_words.append(non_contraction_form)\n",
    "\n",
    "            else:\n",
    "                # print(word)\n",
    "                store_non_contraction_words.append(word)\n",
    "\n",
    "        non_contraction_review = ' '.join(store_non_contraction_words)\n",
    "        return non_contraction_review\n",
    "    else:\n",
    "        return review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_contractions(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove contractions from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    without_contractions_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        # print(\"Review\", text_reviews_idx, \"with possible contraction(s) -- \", text_review)\n",
    "\n",
    "        without_contraction = locate_and_replace_contractions(text_review)\n",
    "\n",
    "        # print(\"Review\", text_reviews_idx, \"without contraction -- \", without_contraction)\n",
    "        # print()\n",
    "\n",
    "        without_contractions_reviews.append(without_contraction)\n",
    "\n",
    "    updated_df['without_contractions'] = without_contractions_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_contractions_df = remove_contractions(no_html_urls_df, 'without_html_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_contractions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_contractions:\")\n",
    "# generate_sample_reviews(no_contractions_df, 'without_contractions', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphabetical_characters(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove Non-alphabetical characters from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the non-alphabetical characters removed\n",
    "    \"\"\"\n",
    "\n",
    "    alphabetical_char_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "    # print(text_reviews)\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "        \n",
    "        if isinstance(text_review, str):\n",
    "\n",
    "            # Check for non-alphabetical characters\n",
    "            has_non_alphabetical_char = bool(re.search(r'[^a-zA-Z]', text_review))\n",
    "            if has_non_alphabetical_char == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has HTML -- \", text_review)\n",
    "                pass\n",
    "            \n",
    "            # Remove non-alphabetical characters\n",
    "            with_alphabetical_char = re.sub(r'[^a-zA-Z\\s]', ' ', text_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"has HTML -- \", with_alphabetical_char)\n",
    "            alphabetical_char_reviews.append(with_alphabetical_char)\n",
    "        else:\n",
    "            alphabetical_char_reviews.append(text_review)\n",
    "\n",
    "    updated_df['with_alpha_chars_only'] = alphabetical_char_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_alpha_chars_df = remove_non_alphabetical_characters(no_contractions_df, 'without_contractions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_alpha_chars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"with_alpha_chars_only:\")\n",
    "# generate_sample_reviews(only_alpha_chars_df, 'with_alpha_chars_only', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Remove extra spaces from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    single_spaced_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "    # print(text_reviews)\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        if isinstance(text_review, str):\n",
    "        # Check if there are any extra spaces\n",
    "            has_extra_space = bool(re.search(r' +', text_review))\n",
    "            if has_extra_space == True:\n",
    "                # print(\"Review\", text_reviews_idx, \"has extra space -- \", text_review)\n",
    "                pass\n",
    "            \n",
    "            # Remove extra spaces\n",
    "            single_spaced_review = re.sub(r' +', ' ', text_review)\n",
    "            # print(\"Review\", text_reviews_idx, \"without extra space -- \", single_spaced_review)\n",
    "            # print()\n",
    "            \n",
    "            single_spaced_reviews.append(single_spaced_review)\n",
    "        else:\n",
    "            single_spaced_reviews.append(text_review)\n",
    "\n",
    "    updated_df['without_extra_space'] = single_spaced_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_extra_space_df = remove_extra_spaces(only_alpha_chars_df, 'with_alpha_chars_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_extra_space_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_extra_space:\")\n",
    "# generate_sample_reviews(no_extra_space_df, 'without_extra_space', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_words(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Filter stop words out from all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    without_stop_words_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]\n",
    "\n",
    "        if isinstance(text_review, str):\n",
    "            text_review_words = word_tokenize(text_review) \n",
    "\n",
    "        \n",
    "\n",
    "            # print(\"Before stop word removal\", text_reviews_idx, \" -- \", text_review)\n",
    "\n",
    "            filtered_review = []\n",
    "\n",
    "            for text_review_words_idx in range(len(text_review_words)):\n",
    "                text_review_word = text_review_words[text_review_words_idx]\n",
    "                \n",
    "                # Check if review word is a stop word\n",
    "                if text_review_word in stop_words:\n",
    "                    # print(\"  Stop word -- \", text_review_word)\n",
    "                    pass\n",
    "                else:\n",
    "                    # print(text_review_word, \" -- is NOT a stop word in review\")\n",
    "                    filtered_review.append(text_review_word)\n",
    "\n",
    "            \n",
    "            filtered_review = \" \".join(filtered_review)\n",
    "            # print(\"After stop word removal\", text_reviews_idx, \" -- \", filtered_review)\n",
    "            # print()\n",
    "            \n",
    "            without_stop_words_reviews.append(filtered_review)\n",
    "        else:\n",
    "            without_stop_words_reviews.append(text_review)\n",
    "        \n",
    "\n",
    "    updated_df['without_stop_words'] = without_stop_words_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_stop_words_df = filter_stop_words(no_extra_space_df, 'without_extra_space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_stop_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_stop_words:\")\n",
    "# generate_sample_reviews(no_stop_words_df, 'without_stop_words', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  \n",
    "\n",
    "- \"A sentence with many words\"\n",
    "    - \"words\" -> word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmentize_review(df:pd.DataFrame, col_name: str):\n",
    "    \"\"\"Lemmentize all reviews\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    df: `pd.DataFrame`\n",
    "        An updated DataFrame with the extra spaces removed\n",
    "    \"\"\"\n",
    "    \n",
    "    lemmed_reviews = []\n",
    "    updated_df = df.copy()\n",
    "    text_reviews = df[col_name].values\n",
    "\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    for text_reviews_idx in range(len(text_reviews)):\n",
    "        text_review = text_reviews[text_reviews_idx]   \n",
    "        if isinstance(text_review, str):     \n",
    "            words_in_review = word_tokenize(text_review) \n",
    "\n",
    "            # print(\"Before lem update\", text_reviews_idx, \" -- \", text_review)\n",
    "            # print(\"Lemmed words\", words_in_review)\n",
    "            \n",
    "\n",
    "            lemmed_sentence = []\n",
    "\n",
    "            # Split review into words\n",
    "            for lemmed_words_idx in range(len(words_in_review)):\n",
    "                word = words_in_review[lemmed_words_idx]\n",
    "                \n",
    "                apply_lemmatization = lem.lemmatize(word)\n",
    "                # print(apply_lemmatization)\n",
    "                \n",
    "                lemmed_sentence.append(apply_lemmatization)\n",
    "                filtered_review = \" \".join(lemmed_sentence)\n",
    "        \n",
    "            # print(\"After lem update -- \", filtered_review)\n",
    "            # print()\n",
    "\n",
    "            lemmed_reviews.append(filtered_review)\n",
    "        else:\n",
    "            lemmed_reviews.append(text_review)\n",
    "\n",
    "    updated_df['lemmed_reviews'] = lemmed_reviews\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmed_df = lemmentize_review(no_stop_words_df, 'without_stop_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"without_unlemmed_words:\")\n",
    "# generate_sample_reviews(lemmed_df, 'lemmed_reviews', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CleanData:\n",
    "#     \"\"\"Perform lower case, remove HTML and URLs, remove contractions, remove non-alphabetical characters, remove extra spaces, remove stop words, and lemmatize\"\"\"\n",
    "\n",
    "#     def preprocess_data():\n",
    "#         reviews_lower_cased = convert_reviews_to_lower_case(sampled_reviews_ratings_df, 'review_body')\n",
    "#         no_html_urls_df = remove_html_and_urls(reviews_lower_cased, 'lower_cased')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 23:23:44,578 : INFO : loading projection weights from /Users/brinkley97/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2024-02-06 23:24:16,713 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/brinkley97/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-02-06T23:24:16.713877', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import gensim.downloader as api\n",
    "pretrained_word_two_vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 23:24:16,724 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-02-06 23:24:16,725 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2024-02-06 23:24:16,725 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2024-02-06T23:24:16.725937', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, col_name: str):\n",
    "        self.df = df\n",
    "        self.col_name = col_name\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: `pd.DataFrame`\n",
    "            The data\n",
    "        \n",
    "        col_name: `str`\n",
    "            Column with reviews\n",
    "\n",
    "        words_in_model: `list`\n",
    "            Words in Word2Vec model\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        text_reviews = self.df[self.col_name].values\n",
    "\n",
    "        for text_reviews_idx in range(len(text_reviews)):\n",
    "            text_review = text_reviews[text_reviews_idx]\n",
    "            # print(text_reviews_idx, \"--\", text_review)\n",
    "\n",
    "            yield utils.simple_preprocess(text_review)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 23:24:16,838 : INFO : collecting all words and their counts\n",
      "2024-02-06 23:24:16,839 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-02-06 23:24:16,966 : INFO : collected 6720 word types from a corpus of 92961 raw words and 1500 sentences\n",
      "2024-02-06 23:24:16,967 : INFO : Creating a fresh vocabulary\n",
      "2024-02-06 23:24:16,970 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 1079 unique words (16.06% of original 6720, drops 5641)', 'datetime': '2024-02-06T23:24:16.970478', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-06 23:24:16,971 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 79887 word corpus (85.94% of original 92961, drops 13074)', 'datetime': '2024-02-06T23:24:16.971057', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-06 23:24:16,976 : INFO : deleting the raw counts dictionary of 6720 items\n",
      "2024-02-06 23:24:16,977 : INFO : sample=0.001 downsamples 69 most-common words\n",
      "2024-02-06 23:24:16,978 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 54762.53494088916 word corpus (68.5%% of prior 79887)', 'datetime': '2024-02-06T23:24:16.978371', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-02-06 23:24:16,985 : INFO : estimated required memory for 1079 words and 300 dimensions: 3129100 bytes\n",
      "2024-02-06 23:24:16,985 : INFO : resetting layer weights\n",
      "2024-02-06 23:24:16,988 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-02-06T23:24:16.988639', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2024-02-06 23:24:16,989 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 1079 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=11 shrink_windows=True', 'datetime': '2024-02-06T23:24:16.989549', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentences <__main__.MyCorpus object at 0x1ff7f2ad0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 23:24:17,228 : INFO : EPOCH 0: training on 92961 raw words (54776 effective words) took 0.2s, 238695 effective words/s\n",
      "2024-02-06 23:24:17,364 : INFO : EPOCH 1: training on 92961 raw words (54719 effective words) took 0.1s, 422268 effective words/s\n",
      "2024-02-06 23:24:17,501 : INFO : EPOCH 2: training on 92961 raw words (54830 effective words) took 0.1s, 421046 effective words/s\n",
      "2024-02-06 23:24:17,634 : INFO : EPOCH 3: training on 92961 raw words (54783 effective words) took 0.1s, 476223 effective words/s\n",
      "2024-02-06 23:24:17,767 : INFO : EPOCH 4: training on 92961 raw words (54808 effective words) took 0.1s, 436040 effective words/s\n",
      "2024-02-06 23:24:17,768 : INFO : Word2Vec lifecycle event {'msg': 'training on 464805 raw words (273916 effective words) took 0.8s, 352099 effective words/s', 'datetime': '2024-02-06T23:24:17.768034', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-02-06 23:24:17,768 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=1079, vector_size=300, alpha=0.025>', 'datetime': '2024-02-06T23:24:17.768550', 'gensim': '4.3.2', 'python': '3.11.4 (main, Jul 25 2023, 17:07:07) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.6.3-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "# sentences = MyCorpus(lemmed_df, 'lemmed_reviews')\n",
    "sentences = MyCorpus(sampled_reviews_ratings_df, 'review_body')\n",
    "print(\"\\nSentences\", sentences)\n",
    "my_model = gensim.models.Word2Vec(sentences=sentences, vector_size=300, window=11, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tempfile\n",
    "\n",
    "# with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "#     temporary_filepath = tmp.name\n",
    "#     # my_model.save(temporary_filepath)\n",
    "#     #\n",
    "#     # The model is now safely stored in the filepath.\n",
    "#     # You can copy it to other machines, share it with others, etc.\n",
    "#     #\n",
    "#     # To load a saved model:\n",
    "#     #\n",
    "#     load_my_pretrained_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar scores\n",
    "\n",
    "[ ] Write summary of differences between their model and my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRetrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'it',\n",
       " 'to',\n",
       " 'and',\n",
       " 'is',\n",
       " 'of',\n",
       " 'for',\n",
       " 'this',\n",
       " 'br',\n",
       " 'in',\n",
       " 'that',\n",
       " 'not',\n",
       " 'you',\n",
       " 'my',\n",
       " 'with',\n",
       " 'but',\n",
       " 'on',\n",
       " 'have',\n",
       " 'was',\n",
       " 'they',\n",
       " 'printer',\n",
       " 'are',\n",
       " 'one',\n",
       " 'as',\n",
       " 'so',\n",
       " 'be',\n",
       " 'very',\n",
       " 'all',\n",
       " 'if',\n",
       " 'use',\n",
       " 'or',\n",
       " 'when',\n",
       " 'out',\n",
       " 'ink',\n",
       " 'just',\n",
       " 'will',\n",
       " 'had',\n",
       " 'can',\n",
       " 'would',\n",
       " 'at',\n",
       " 'these',\n",
       " 'from',\n",
       " 'good',\n",
       " 'up',\n",
       " 'them',\n",
       " 'me',\n",
       " 'like',\n",
       " 'great',\n",
       " 'print',\n",
       " 'get',\n",
       " 'work',\n",
       " 'no',\n",
       " 'time',\n",
       " 'do',\n",
       " 'only',\n",
       " 'an',\n",
       " 'has',\n",
       " 'more',\n",
       " 'product',\n",
       " 'than',\n",
       " 'don',\n",
       " 'what',\n",
       " 'well',\n",
       " 'quality',\n",
       " 'phone',\n",
       " 'paper',\n",
       " 'because',\n",
       " 'there',\n",
       " 'about',\n",
       " 'buy',\n",
       " 'we',\n",
       " 'other',\n",
       " 'after',\n",
       " 'your',\n",
       " 'which',\n",
       " 'much',\n",
       " 'even',\n",
       " 'color',\n",
       " 'does',\n",
       " 'am',\n",
       " 'works',\n",
       " 'little',\n",
       " 'used',\n",
       " 'really',\n",
       " 'also',\n",
       " 'cartridge',\n",
       " 'off',\n",
       " 'price',\n",
       " 'cartridges',\n",
       " 'now',\n",
       " 'some',\n",
       " 'bought',\n",
       " 'then',\n",
       " 'by',\n",
       " 've',\n",
       " 'printing',\n",
       " 'new',\n",
       " 'first',\n",
       " 'using',\n",
       " 'nice',\n",
       " 'were',\n",
       " 'back',\n",
       " 'too',\n",
       " 'did',\n",
       " 'been',\n",
       " 'need',\n",
       " 'hp',\n",
       " 'could',\n",
       " 'any',\n",
       " 'still',\n",
       " 'again',\n",
       " 'got',\n",
       " 'two',\n",
       " 'their',\n",
       " 'over',\n",
       " 'easy',\n",
       " 'black',\n",
       " 'better',\n",
       " 'didn',\n",
       " 'fine',\n",
       " 'doesn',\n",
       " 'money',\n",
       " 'however',\n",
       " 'love',\n",
       " 'problem',\n",
       " 'pen',\n",
       " 'way',\n",
       " 'worked',\n",
       " 'how',\n",
       " 'make',\n",
       " 'before',\n",
       " 'should',\n",
       " 'small',\n",
       " 'put',\n",
       " 'long',\n",
       " 'every',\n",
       " 'never',\n",
       " 'want',\n",
       " 'purchased',\n",
       " 'same',\n",
       " 'through',\n",
       " 'lot',\n",
       " 'last',\n",
       " 'set',\n",
       " 'year',\n",
       " 'few',\n",
       " 'many',\n",
       " 'made',\n",
       " 'since',\n",
       " 'makes',\n",
       " 'software',\n",
       " 'plastic',\n",
       " 'another',\n",
       " 'into',\n",
       " 'find',\n",
       " 'day',\n",
       " 'months',\n",
       " 'box',\n",
       " 'its',\n",
       " 'see',\n",
       " 'right',\n",
       " 'pages',\n",
       " 'say',\n",
       " 'amazon',\n",
       " 'each',\n",
       " 'recommend',\n",
       " 'go',\n",
       " 'think',\n",
       " 'look',\n",
       " 'both',\n",
       " 'enough',\n",
       " 'our',\n",
       " 'old',\n",
       " 'try',\n",
       " 'came',\n",
       " 'bit',\n",
       " 'able',\n",
       " 'down',\n",
       " 'machine',\n",
       " 'going',\n",
       " 'thing',\n",
       " 'without',\n",
       " 'years',\n",
       " 'll',\n",
       " 'take',\n",
       " 'though',\n",
       " 'home',\n",
       " 'know',\n",
       " 'computer',\n",
       " 'who',\n",
       " 'light',\n",
       " 'something',\n",
       " 'sure',\n",
       " 'hard',\n",
       " 'item',\n",
       " 'while',\n",
       " 'return',\n",
       " 'happy',\n",
       " 'pens',\n",
       " 'tried',\n",
       " 'purchase',\n",
       " 'case',\n",
       " 'order',\n",
       " 'working',\n",
       " 'most',\n",
       " 'found',\n",
       " 'office',\n",
       " 'bad',\n",
       " 'cheap',\n",
       " 'needed',\n",
       " 'times',\n",
       " 'he',\n",
       " 'far',\n",
       " 'come',\n",
       " 'white',\n",
       " 'labels',\n",
       " 'cost',\n",
       " 'photo',\n",
       " 'scanner',\n",
       " 'different',\n",
       " 'seems',\n",
       " 'problems',\n",
       " 'pretty',\n",
       " 'looking',\n",
       " 'fit',\n",
       " 'where',\n",
       " 'received',\n",
       " 'always',\n",
       " 'month',\n",
       " 'page',\n",
       " 'size',\n",
       " 'looks',\n",
       " 'ordered',\n",
       " 'replace',\n",
       " 'printed',\n",
       " 'side',\n",
       " 'big',\n",
       " 'printers',\n",
       " 'getting',\n",
       " 'unit',\n",
       " 're',\n",
       " 'trying',\n",
       " 'give',\n",
       " 'once',\n",
       " 'place',\n",
       " 'less',\n",
       " 'shipping',\n",
       " 'cards',\n",
       " 'won',\n",
       " 'brother',\n",
       " 'picture',\n",
       " 'actually',\n",
       " 'power',\n",
       " 'buying',\n",
       " 'things',\n",
       " 'thought',\n",
       " 'cover',\n",
       " 'being',\n",
       " 'hold',\n",
       " 'read',\n",
       " 'having',\n",
       " 'anything',\n",
       " 'full',\n",
       " 'number',\n",
       " 'went',\n",
       " 'fast',\n",
       " 'easily',\n",
       " 'around',\n",
       " 'line',\n",
       " 'high',\n",
       " 'may',\n",
       " 'service',\n",
       " 'support',\n",
       " 'low',\n",
       " 'phones',\n",
       " 'perfect',\n",
       " 'system',\n",
       " 'keep',\n",
       " 'wanted',\n",
       " 'couple',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'deal',\n",
       " 'brand',\n",
       " 'top',\n",
       " 'worth',\n",
       " 'next',\n",
       " 'wireless',\n",
       " 'people',\n",
       " 'reviews',\n",
       " 'said',\n",
       " 'stars',\n",
       " 'itself',\n",
       " 'isn',\n",
       " 'business',\n",
       " 'colors',\n",
       " 'away',\n",
       " 'comes',\n",
       " 'quite',\n",
       " 'ever',\n",
       " 'extra',\n",
       " 'inside',\n",
       " 'almost',\n",
       " 'epson',\n",
       " 'several',\n",
       " 'probably',\n",
       " 'clear',\n",
       " 'wish',\n",
       " 'job',\n",
       " 'write',\n",
       " 'waste',\n",
       " 'feel',\n",
       " 'three',\n",
       " 'prints',\n",
       " 'until',\n",
       " 'dry',\n",
       " 'longer',\n",
       " 'second',\n",
       " 'everything',\n",
       " 'pay',\n",
       " 'sent',\n",
       " 'pencil',\n",
       " 'best',\n",
       " 'call',\n",
       " 'canon',\n",
       " 'gave',\n",
       " 'disappointed',\n",
       " 'part',\n",
       " 'replacement',\n",
       " 'customer',\n",
       " 'half',\n",
       " 'own',\n",
       " 'review',\n",
       " 'reason',\n",
       " 'update',\n",
       " 'arrived',\n",
       " 'tray',\n",
       " 'end',\n",
       " 'instead',\n",
       " 'piece',\n",
       " 'already',\n",
       " 'issue',\n",
       " 'quickly',\n",
       " 'point',\n",
       " 'screen',\n",
       " 'either',\n",
       " 'original',\n",
       " 'took',\n",
       " 'maybe',\n",
       " 'head',\n",
       " 'yet',\n",
       " 'seem',\n",
       " 'needs',\n",
       " 'ones',\n",
       " 'company',\n",
       " 'those',\n",
       " 'toner',\n",
       " 'why',\n",
       " 'left',\n",
       " 'large',\n",
       " 'sound',\n",
       " 'started',\n",
       " 'others',\n",
       " 'days',\n",
       " 'scan',\n",
       " 'she',\n",
       " 'model',\n",
       " 'usb',\n",
       " 'feature',\n",
       " 'excellent',\n",
       " 'battery',\n",
       " 'photos',\n",
       " 'guess',\n",
       " 'ago',\n",
       " 'etc',\n",
       " 'lines',\n",
       " 'button',\n",
       " 'his',\n",
       " 'design',\n",
       " 'nothing',\n",
       " 'projector',\n",
       " 'whole',\n",
       " 'items',\n",
       " 'help',\n",
       " 'documents',\n",
       " 'clean',\n",
       " 'must',\n",
       " 'together',\n",
       " 'buttons',\n",
       " 'features',\n",
       " 'seller',\n",
       " 'laptop',\n",
       " 'although',\n",
       " 'change',\n",
       " 'error',\n",
       " 'let',\n",
       " 'sometimes',\n",
       " 'such',\n",
       " 'hand',\n",
       " 'wall',\n",
       " 'calendar',\n",
       " 'under',\n",
       " 'wrong',\n",
       " 'heavy',\n",
       " 'room',\n",
       " 'book',\n",
       " 'fact',\n",
       " 'minutes',\n",
       " 'card',\n",
       " 'highly',\n",
       " 'week',\n",
       " 'here',\n",
       " 'per',\n",
       " 'device',\n",
       " 'exactly',\n",
       " 'pleased',\n",
       " 'cut',\n",
       " 'gets',\n",
       " 'might',\n",
       " 'issues',\n",
       " 'bottom',\n",
       " 'caller',\n",
       " 'us',\n",
       " 'within',\n",
       " 'id',\n",
       " 'open',\n",
       " 'often',\n",
       " 'real',\n",
       " 'function',\n",
       " 'run',\n",
       " 'poor',\n",
       " 'package',\n",
       " 'ok',\n",
       " 'reading',\n",
       " 'lasted',\n",
       " 'name',\n",
       " 'pencils',\n",
       " 'instructions',\n",
       " 'tape',\n",
       " 'front',\n",
       " 'says',\n",
       " 'cannot',\n",
       " 'included',\n",
       " 'base',\n",
       " 'broke',\n",
       " 'desk',\n",
       " 'hours',\n",
       " 'definitely',\n",
       " 'tell',\n",
       " 'message',\n",
       " 'pictures',\n",
       " 'worst',\n",
       " 'pad',\n",
       " 'plus',\n",
       " 'wasn',\n",
       " 'turn',\n",
       " 'weeks',\n",
       " 'writing',\n",
       " 'keys',\n",
       " 'okay',\n",
       " 'stick',\n",
       " 'store',\n",
       " 'shredder',\n",
       " 'add',\n",
       " 'fax',\n",
       " 'installed',\n",
       " 'handle',\n",
       " 'batteries',\n",
       " 'red',\n",
       " 'send',\n",
       " 'someone',\n",
       " 'life',\n",
       " 'perfectly',\n",
       " 'bag',\n",
       " 'school',\n",
       " 'finally',\n",
       " 'products',\n",
       " 'weight',\n",
       " 'type',\n",
       " 'done',\n",
       " 'owned',\n",
       " 'stay',\n",
       " 'apart',\n",
       " 'opened',\n",
       " 'erase',\n",
       " 'returned',\n",
       " 'uses',\n",
       " 'expect',\n",
       " 'sheets',\n",
       " 'unfortunately',\n",
       " 'else',\n",
       " 'display',\n",
       " 'laser',\n",
       " 'completely',\n",
       " 'pack',\n",
       " 'headset',\n",
       " 'fairly',\n",
       " 'running',\n",
       " 'kids',\n",
       " 'lost',\n",
       " 'past',\n",
       " 'making',\n",
       " 'sturdy',\n",
       " 'push',\n",
       " 'overall',\n",
       " 'thin',\n",
       " 'looked',\n",
       " 'idea',\n",
       " 'files',\n",
       " 'sheet',\n",
       " 'due',\n",
       " 'document',\n",
       " 'higher',\n",
       " 'start',\n",
       " 'online',\n",
       " 'person',\n",
       " 'returning',\n",
       " 'super',\n",
       " 'copies',\n",
       " 'calls',\n",
       " 'surface',\n",
       " 'keyboard',\n",
       " 'decent',\n",
       " 'network',\n",
       " 'stand',\n",
       " 'goes',\n",
       " 'third',\n",
       " 'inch',\n",
       " 'replaced',\n",
       " 'palm',\n",
       " 'space',\n",
       " 'couldn',\n",
       " 'wouldn',\n",
       " 'fits',\n",
       " 'warranty',\n",
       " 'simple',\n",
       " 'close',\n",
       " 'star',\n",
       " 'information',\n",
       " 'handset',\n",
       " 'non',\n",
       " 'voice',\n",
       " 'image',\n",
       " 'usually',\n",
       " 'blue',\n",
       " 'label',\n",
       " 'notes',\n",
       " 'list',\n",
       " 'advertised',\n",
       " 'cheaper',\n",
       " 'especially',\n",
       " 'between',\n",
       " 'free',\n",
       " 'packaging',\n",
       " 'shipped',\n",
       " 'broken',\n",
       " 'haven',\n",
       " 'unless',\n",
       " 'mode',\n",
       " 'recognize',\n",
       " 'care',\n",
       " 'anyone',\n",
       " 'scanning',\n",
       " 'amount',\n",
       " 'yes',\n",
       " 'hour',\n",
       " 'rather',\n",
       " 'properly',\n",
       " 'cleaning',\n",
       " 'parts',\n",
       " 'during',\n",
       " 'quick',\n",
       " 'smooth',\n",
       " 'functions',\n",
       " 'user',\n",
       " 'believe',\n",
       " 'mouse',\n",
       " 'metal',\n",
       " 'called',\n",
       " 'numbers',\n",
       " 'her',\n",
       " 'break',\n",
       " 'regular',\n",
       " 'hear',\n",
       " 'pc',\n",
       " 'markers',\n",
       " 'son',\n",
       " 'tech',\n",
       " 'option',\n",
       " 'empty',\n",
       " 'panasonic',\n",
       " 'later',\n",
       " 'recently',\n",
       " 'windows',\n",
       " 'junk',\n",
       " 'recommended',\n",
       " 'constantly',\n",
       " 'sharp',\n",
       " 'stuff',\n",
       " 'doing',\n",
       " 'volume',\n",
       " 'saw',\n",
       " 'noise',\n",
       " 'kind',\n",
       " 'ip',\n",
       " 'slide',\n",
       " 'cool',\n",
       " 'papers',\n",
       " 'yellow',\n",
       " 'four',\n",
       " 'setup',\n",
       " 'cons',\n",
       " 'pocket',\n",
       " 'twice',\n",
       " 'single',\n",
       " 'mine',\n",
       " 'simply',\n",
       " 'save',\n",
       " 'calculator',\n",
       " 'lots',\n",
       " 'books',\n",
       " 'takes',\n",
       " 'connection',\n",
       " 'version',\n",
       " 'house',\n",
       " 'impossible',\n",
       " 'table',\n",
       " 'allow',\n",
       " 'solid',\n",
       " 'larger',\n",
       " 'touch',\n",
       " 'least',\n",
       " 'charge',\n",
       " 'short',\n",
       " 'email',\n",
       " 'spend',\n",
       " 'professional',\n",
       " 'board',\n",
       " 'loud',\n",
       " 'marker',\n",
       " 'feels',\n",
       " 'annoying',\n",
       " 'stopped',\n",
       " 'taking',\n",
       " 'difficult',\n",
       " 'remove',\n",
       " 'total',\n",
       " 'smaller',\n",
       " 'anymore',\n",
       " 'speaker',\n",
       " 'strong',\n",
       " 'area',\n",
       " 'flimsy',\n",
       " 'clearly',\n",
       " 'pull',\n",
       " 'feed',\n",
       " 'plug',\n",
       " 'myself',\n",
       " 'hope',\n",
       " 'value',\n",
       " 'available',\n",
       " 'double',\n",
       " 'huge',\n",
       " 'true',\n",
       " 'key',\n",
       " 'told',\n",
       " 'gone',\n",
       " 'refill',\n",
       " 'multiple',\n",
       " 'loved',\n",
       " 'talk',\n",
       " 'address',\n",
       " 'helpful',\n",
       " 'edges',\n",
       " 'slow',\n",
       " 'colored',\n",
       " 'cord',\n",
       " 'cordless',\n",
       " 'seen',\n",
       " 'seemed',\n",
       " 'correct',\n",
       " 'five',\n",
       " 'play',\n",
       " 'pieces',\n",
       " 'easier',\n",
       " 'compatible',\n",
       " 'absolutely',\n",
       " 'leave',\n",
       " 'glue',\n",
       " 'slightly',\n",
       " 'description',\n",
       " 'contacted',\n",
       " 'runs',\n",
       " 'ended',\n",
       " 'otherwise',\n",
       " 'cable',\n",
       " 'lamp',\n",
       " 'results',\n",
       " 'dark',\n",
       " 'fix',\n",
       " 'built',\n",
       " 'pros',\n",
       " 'experience',\n",
       " 'ease',\n",
       " 'inkjet',\n",
       " 'dell',\n",
       " 'lead',\n",
       " 'shows',\n",
       " 'show',\n",
       " 'based',\n",
       " 'process',\n",
       " 'range',\n",
       " 'correctly',\n",
       " 'binder',\n",
       " 'holds',\n",
       " 'fountain',\n",
       " 'users',\n",
       " 'control',\n",
       " 'complaint',\n",
       " 'contact',\n",
       " 'except',\n",
       " 'course',\n",
       " 'everyone',\n",
       " 'ability',\n",
       " 'wait',\n",
       " 'decided',\n",
       " 'talking',\n",
       " 'thanks',\n",
       " 'cell',\n",
       " 'kept',\n",
       " 'bags',\n",
       " 'ti',\n",
       " 'test',\n",
       " 'tip',\n",
       " 'bigger',\n",
       " 'text',\n",
       " 'noticed',\n",
       " 'corners',\n",
       " 'terrible',\n",
       " 'setting',\n",
       " 'impressed',\n",
       " 'web',\n",
       " 'recorder',\n",
       " 'normal',\n",
       " 'older',\n",
       " 'outside',\n",
       " 'none',\n",
       " 'paid',\n",
       " 'manual',\n",
       " 'file',\n",
       " 'rest',\n",
       " 'inks',\n",
       " 'speed',\n",
       " 'additional',\n",
       " 'today',\n",
       " 'useful',\n",
       " 'carry',\n",
       " 'useless',\n",
       " 'main',\n",
       " 'heads',\n",
       " 'nicely',\n",
       " 'note',\n",
       " 'magnets',\n",
       " 'door',\n",
       " 'fall',\n",
       " 'letters',\n",
       " 'auto',\n",
       " 'hands',\n",
       " 'husband',\n",
       " 'purple',\n",
       " 'held',\n",
       " 'stock',\n",
       " 'designed',\n",
       " 'move',\n",
       " 'program',\n",
       " 'felt',\n",
       " 'comfortable',\n",
       " 'certainly',\n",
       " 'tool',\n",
       " 'slides',\n",
       " 'stop',\n",
       " 'consider',\n",
       " 'scans',\n",
       " 'liked',\n",
       " 'future',\n",
       " 'solution',\n",
       " 'xp',\n",
       " 'stores',\n",
       " 'options',\n",
       " 'frame',\n",
       " 'folders',\n",
       " 'choice',\n",
       " 'connect',\n",
       " 'load',\n",
       " 'friend',\n",
       " 'mind',\n",
       " 'images',\n",
       " 'crazy',\n",
       " 'fun',\n",
       " 'wasted',\n",
       " 'operate',\n",
       " 'saying',\n",
       " 'luck',\n",
       " 'mistake',\n",
       " 'lexmark',\n",
       " 'inexpensive',\n",
       " 'bright',\n",
       " 'led',\n",
       " 'priced',\n",
       " 'functional',\n",
       " 'actual',\n",
       " 'answering',\n",
       " 'plan',\n",
       " 'compared',\n",
       " 'wonderful',\n",
       " 'important',\n",
       " 'daily',\n",
       " 'word',\n",
       " 'extremely',\n",
       " 'fully',\n",
       " 'lid',\n",
       " 'digital',\n",
       " 'staples',\n",
       " 'performance',\n",
       " 'basically',\n",
       " 'glad',\n",
       " 'technical',\n",
       " 'mute',\n",
       " 'lose',\n",
       " 'chair',\n",
       " 'mail',\n",
       " 'check',\n",
       " 'standard',\n",
       " 'similar',\n",
       " 'horrible',\n",
       " 'jams',\n",
       " 'mfc',\n",
       " 'awesome',\n",
       " 'bar',\n",
       " 'google',\n",
       " 'app',\n",
       " 'feeder',\n",
       " 'construction',\n",
       " 'vendor',\n",
       " 'become',\n",
       " 'paint',\n",
       " 'nearly',\n",
       " 'tiny',\n",
       " 'offered',\n",
       " 'him',\n",
       " 'via',\n",
       " 'mentioned',\n",
       " 'putting',\n",
       " 'drivers',\n",
       " 'party',\n",
       " 'wallet',\n",
       " 'spent',\n",
       " 'honestly',\n",
       " 'sort',\n",
       " 'delivery',\n",
       " 'gives',\n",
       " 'stuck',\n",
       " 'lightweight',\n",
       " 'trouble',\n",
       " 'material',\n",
       " 'keeps',\n",
       " 'ring',\n",
       " 'green',\n",
       " 'lights',\n",
       " 'refund',\n",
       " 'entire',\n",
       " 'style',\n",
       " 'weak',\n",
       " 'level',\n",
       " 'words',\n",
       " 'mess',\n",
       " 'immediately',\n",
       " 'pro',\n",
       " 'costs',\n",
       " 'missing',\n",
       " 'student',\n",
       " 'minimal',\n",
       " 'reasonable',\n",
       " 'charger',\n",
       " 'given',\n",
       " 'install',\n",
       " 'difference',\n",
       " 'include',\n",
       " 'provide',\n",
       " 'edge',\n",
       " 'sending',\n",
       " 'sharpener',\n",
       " 'along',\n",
       " 'match',\n",
       " 'ran',\n",
       " 'holder',\n",
       " 'driver',\n",
       " 'eraser',\n",
       " 'choose',\n",
       " 'connected',\n",
       " 'purchasing',\n",
       " 'matter',\n",
       " 'defective',\n",
       " 'previous',\n",
       " 'bent',\n",
       " 'handy',\n",
       " 'replacing',\n",
       " 'reliable',\n",
       " 'realized',\n",
       " 'envelopes',\n",
       " 'answer',\n",
       " 'receive',\n",
       " 'messages',\n",
       " 'leaving',\n",
       " 'duty',\n",
       " 'including',\n",
       " 'ps',\n",
       " 'please',\n",
       " 'durable',\n",
       " 'disappointing',\n",
       " 'date',\n",
       " 'refurbished',\n",
       " 'fantastic',\n",
       " 'loose',\n",
       " 'wants',\n",
       " 'local',\n",
       " 'fan',\n",
       " 'beautiful',\n",
       " 'fell',\n",
       " 'cute',\n",
       " 'folder',\n",
       " 'christmas',\n",
       " 'sealed',\n",
       " 'written',\n",
       " 'negative',\n",
       " 'jammed',\n",
       " 'above',\n",
       " 'straight',\n",
       " 'careful',\n",
       " 'site',\n",
       " 'internet',\n",
       " 'chip',\n",
       " 'pick',\n",
       " 'special',\n",
       " 'means',\n",
       " 'seconds',\n",
       " 'against',\n",
       " 'sided',\n",
       " 'hardware',\n",
       " 'scanned',\n",
       " 'streaks',\n",
       " 'output',\n",
       " 'gotten',\n",
       " 'sides',\n",
       " 'projects',\n",
       " 'considering',\n",
       " 'post',\n",
       " 'saved',\n",
       " 'stylus',\n",
       " 'soon',\n",
       " 'worse',\n",
       " 'equipment',\n",
       " 'telephone',\n",
       " 'removed',\n",
       " 'adjust',\n",
       " 'figure',\n",
       " 'changed',\n",
       " 'roll',\n",
       " 'stops',\n",
       " 'opinion',\n",
       " 'rough',\n",
       " 'wood',\n",
       " 'crap',\n",
       " 'loves',\n",
       " 'manufacturer',\n",
       " 'sticky',\n",
       " 'described',\n",
       " 'air',\n",
       " 'turned',\n",
       " 'shut',\n",
       " 'hdmi',\n",
       " 'gold',\n",
       " 'clip',\n",
       " 'gift',\n",
       " 'reasonably',\n",
       " 'settings',\n",
       " 'playing',\n",
       " 'rings',\n",
       " 'dollars',\n",
       " 'usage',\n",
       " 'beat',\n",
       " 'aren',\n",
       " 'starting',\n",
       " 'multi',\n",
       " 'leaked',\n",
       " 'poster',\n",
       " 'computers',\n",
       " 'therefore',\n",
       " 'listed',\n",
       " 'bother',\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pretrained_model = my_model.wv\n",
    "# my_pretrained_model = load_my_pretrained_model.wv\n",
    "my_pretrained_model.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = pretrained_word_two_vec_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)\n",
    "\n",
    "# my_result = my_pretrained_model.most_similar(positive=['woman', 'king'], negative=['man', 'men'], topn=10)\n",
    "# print(my_result)\n",
    "# my_result = my_pretrained_model.most_similar(positive=['they', 'customers'], negative=['storage', 'despite'], topn=10)\n",
    "# print(my_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model_words = get_model_vocabulary(my_model.wv)\n",
    "# my_model_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(df: pd.DataFrame, col_name: str, model_to_use):\n",
    "    \"\"\"Extract word embeddings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    model_to_use:\n",
    "        Either the pretrained model or my pretrained model\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    sentence_vectorized = []\n",
    "    mean_sentences_vectorized = []\n",
    "    sentences = df[col_name].values\n",
    "\n",
    "    for sentences_idx in range(len(sentences)):\n",
    "        vectorized_words = []\n",
    "        sentence = sentences[sentences_idx]\n",
    "        # print(\"Sentence\", sentences_idx)\n",
    "        # print(\"Sentence\", sentences_idx, \"Pre-vectorized -- \", sentence)\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word in model_to_use.key_to_index:\n",
    "                vector_of_word = model_to_use[word]\n",
    "                vectorized_words.append(vector_of_word)\n",
    "                # print(\"--->\", word, \"is in model with vector lenght of\", len(vector_of_word))\n",
    "            else:\n",
    "                vector_of_word = np.random.rand(model_to_use.vector_size)\n",
    "                vectorized_words.append(vector_of_word)\n",
    "                \n",
    "        sentence_vectorized.append(vectorized_words)\n",
    "        # print(\"Sentence\", sentences_idx, \"Post-vectorized \\n\")\n",
    "\n",
    "        mean_of_sentence = np.mean(sentence_vectorized[sentences_idx], axis=0)\n",
    "        # print(len(mean_of_sentence), mean_of_sentence)\n",
    "        mean_sentences_vectorized.append(mean_of_sentence)\n",
    "\n",
    "\n",
    "    return mean_sentences_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(pre_trained_words), len(my_model_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_embeddings_df = sampled_reviews_ratings_df.dropna(subset=['binary_review_class'])\n",
    "len(binary_embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained\n"
     ]
    }
   ],
   "source": [
    "print(\"Pretrained\")\n",
    "# pretrained_embeddings = word_embeddings(lemmed_df, 'lemmed_reviews', pretrained_word_two_vec_model)\n",
    "pretrained_embeddings = word_embeddings(binary_embeddings_df, 'review_body', pretrained_word_two_vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 300)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = np.array(pretrained_embeddings)\n",
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My-pretrained\n"
     ]
    }
   ],
   "source": [
    "print(\"My-pretrained\")\n",
    "# my_embeddings = word_embeddings(lemmed_df, 'lemmed_reviews', my_pretrained_model)\n",
    "my_embeddings = word_embeddings(binary_embeddings_df, 'review_body', my_pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 300)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embeddings = np.array(my_embeddings)\n",
    "my_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # embeddings_df = lemmed_df.iloc[:, [5, 1, 12]]\n",
    "# embeddings_df = binary_embeddings_df\n",
    "# embeddings_df['pretrained_embeddings'] = pretrained_embeddings\n",
    "# embeddings_df['my_embeddings'] = my_embeddings\n",
    "# embeddings_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_feature_extraction(df: pd.DataFrame, col_name: str):\n",
    "    \"\"\"Extract the TF-IDF features from the reviews.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: `pd.DataFrame`\n",
    "        The data\n",
    "    \n",
    "    col_name: `str`\n",
    "        Column with reviews\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    tf_idf_features:\n",
    "        A matrix containing the TF-IDF features extracted\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tf_idf_features = vectorizer.fit_transform(df[col_name])\n",
    "\n",
    "    return tf_idf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_features = tf_idf_feature_extraction(lemmed_df, 'lemmed_reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_embeddings_df['star_rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 3.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiments = lemmed_df['sentiment']\n",
    "# sentiments.shape\n",
    "\n",
    "review_class = binary_embeddings_df['binary_review_class']\n",
    "review_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(embeddings, col_name):\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pretrained_embeddings, review_class, test_size=0.2, random_state=42)\n",
    "my_X_train, my_X_test, my_y_train, my_y_test = train_test_split(my_embeddings, review_class, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 300), (960,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 300), (240,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models + Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(y_true, y_prediction):\n",
    "    return sklearn.metrics.accuracy_score(y_true, y_prediction)\n",
    "\n",
    "def eval_precision(y_true, y_prediction):\n",
    "    return sklearn.metrics.precision_score(y_true, y_prediction)\n",
    "\n",
    "def eval_recall(y_true, y_prediction):\n",
    "    return sklearn.metrics.recall_score(y_true, y_prediction)\n",
    "\n",
    "def eval_f1_score(y_true, y_prediction):\n",
    "    return sklearn.metrics.f1_score(y_true, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_metric(y_train_true, y_train_predictions):\n",
    "    accuracy = eval_accuracy(y_train_true, y_train_predictions)\n",
    "    # precision = eval_precision(y_train_true, y_train_predictions)\n",
    "    # recall = eval_recall(y_train_true, y_train_predictions)\n",
    "    # f1 = eval_f1_score(y_train_true, y_train_predictions)\n",
    "\n",
    "    metrics_dict = {\n",
    "        'Accuracy': accuracy,\n",
    "        # 'Precision': precision,\n",
    "        # 'Recall': recall,\n",
    "        # 'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "def test_eval_metric(y_test_true, y_test_predictions):\n",
    "    accuracy = eval_accuracy(y_test_true, y_test_predictions)\n",
    "    # precision = eval_precision(y_test_true, y_test_predictions)\n",
    "    # recall = eval_recall(y_test_true, y_test_predictions)\n",
    "    # f1 = eval_f1_score(y_test_true, y_test_predictions)\n",
    "\n",
    "    metrics_dict = {\n",
    "        'Accuracy': accuracy,\n",
    "        # 'Precision': precision,\n",
    "        # 'Recall': recall,\n",
    "        # 'F1 Score': f1\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_model(X_train, X_test, y_train, y_test): \n",
    "\n",
    "    technique = Perceptron(tol=1e-3, random_state=0)\n",
    "    technique.fit(X_train, y_train)\n",
    "    y_train_predictions = technique.predict(X_train)\n",
    "    y_test_predictions = technique.predict(X_test)\n",
    "\n",
    "\n",
    "    train_metrics = train_eval_metric(y_train, y_train_predictions)\n",
    "    test_metrics = test_eval_metric(y_test, y_test_predictions)\n",
    "\n",
    "    return train_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_train_metrics, perceptron_test_metrics = perceptron_model(X_train, X_test, y_train, y_test)\n",
    "my_perceptron_train_metrics, my_perceptron_test_metrics = perceptron_model(my_X_train, my_X_test, my_y_train, my_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.7052083333333333}, {'Accuracy': 0.6583333333333333})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_train_metrics, perceptron_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.5333333333333333}, {'Accuracy': 0.5041666666666667})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_perceptron_train_metrics, my_perceptron_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(X_train, X_test, y_train, y_test): \n",
    "\n",
    "    technique = LinearSVC(tol=1e-3, random_state=0)\n",
    "    technique.fit(X_train, y_train)\n",
    "    y_train_predictions = technique.predict(X_train)\n",
    "    y_test_predictions = technique.predict(X_test)\n",
    "\n",
    "\n",
    "    train_metrics = train_eval_metric(y_train, y_train_predictions)\n",
    "    test_metrics = test_eval_metric(y_test, y_test_predictions)\n",
    "\n",
    "    return train_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svm_train_metrics, svm_test_metrics = svm_model(X_train, X_test, y_train, y_test)\n",
    "my_svm_train_metrics, my_svm_test_metrics = svm_model(my_X_train, my_X_test, my_y_train, my_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.8354166666666667}, {'Accuracy': 0.7208333333333333})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train_metrics, svm_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Accuracy': 0.7375}, {'Accuracy': 0.525})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_svm_train_metrics, my_svm_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(X_train, X_test, y_train, y_test): \n",
    "\n",
    "    technique = LogisticRegression(random_state=0)\n",
    "    technique.fit(X_train, y_train)\n",
    "    y_train_predictions = technique.predict(X_train)\n",
    "    y_test_predictions = technique.predict(X_test)\n",
    "\n",
    "\n",
    "    train_metrics = train_eval_metric(y_train, y_train_predictions)\n",
    "    test_metrics = test_eval_metric(y_test, y_test_predictions)\n",
    "\n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression_train_metrics, logistic_regression_test_metrics = logistic_regression_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_regression_train_metrics, logistic_regression_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_model(X_train, X_test, y_train, y_test): \n",
    "\n",
    "    technique = MultinomialNB()\n",
    "    technique.fit(X_train.toarray(), y_train)\n",
    "    y_train_predictions = technique.predict(X_train)\n",
    "    y_test_predictions = technique.predict(X_test)\n",
    "\n",
    "    train_metrics = train_eval_metric(y_train, y_train_predictions)\n",
    "    test_metrics = test_eval_metric(y_test, y_test_predictions)\n",
    "\n",
    "    return train_metrics, test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_bayes_train_metrics, naive_bayes_test_metrics = naive_bayes_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_bayes_train_metrics, naive_bayes_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
