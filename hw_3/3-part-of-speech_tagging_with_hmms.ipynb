{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3-Part-of-Speech Tagging with HMMs + Decoding Techniques (Greedy and Viterbi)\n",
    "\n",
    "- Detravious Jamari Brinkley\n",
    "- CSCI-544: Applied Natural Language Processing\n",
    "- python version: 3.11.4\n",
    "\n",
    "---\n",
    "\n",
    "1. Part-of-Speech (POS) Tagging [a type of sequence labelling task where of a given word, assign the part of speech]\n",
    "2. HMMs (Hidden Markov Model) [a generative-based model that's used for POS Tagging]\n",
    "    1. Generative-based [provides the probabilities for all possible combinations of values of variables in the set using the joint distribution]\n",
    "    2. With POS Tagging: Given a sequence of observations (sentences), the task is to infer the most likely sequence of hidden states (POS Tags) that could have generated the observed data.\n",
    "3. **Decoding Techniques:**\n",
    "    1. Greedy [find the optimal (OPT) solution at each step]\n",
    "    2. Viterbi [make use of dynammic programming to find the OPT solution with backtracking while searching the entire search space]\n",
    "4. **Notes of the data and given files:**\n",
    "    - Dataset: Wall Street Journal section of the Penn Treebank\n",
    "    - Folder named `data` with the following files:\n",
    "        1. `train`, sentences *with* human-annotated POS Tags\n",
    "        2. `dev`, sentences *with* human-annotated POS Tags\n",
    "        3. `test`, sentences *without* POS Tags, thus predict the POS Tags\n",
    "    - Format: Blank like at the end of each sentence. Each line contains 3 items separated by the `\\t`, the tab symbol. These three items are\n",
    "        1. Index of the word in the sentence\n",
    "        2. Word type\n",
    "        3. POS Tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/brinkley97/opt/anaconda3/envs/nlp/lib/python3.11/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_15609/990994264.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Update Data\n",
    "- [x] Find a way to separate sentences when loading the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str, file_name: str, config_index: bool = True):\n",
    "    \n",
    "    if config_index == True:\n",
    "        file =  file_path + file_name\n",
    "        open_df = pd.read_table(file, skip_blank_lines=False)\n",
    "        open_df = open_df.set_index('1')\n",
    "        \n",
    "    return open_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_columns(df: pd.DataFrame, new_columns_name: list, about: str) -> pd.DataFrame:  \n",
    "    \"\"\"Update the columns of the dataframe if first column is data needed\"\"\"  \n",
    "\n",
    "    N_columns = len(df.columns.to_list())\n",
    "\n",
    "    if N_columns == 1:\n",
    "        print(about, \"has 1 column\")\n",
    "        word = df.columns.to_list()[0]\n",
    "        new_row = pd.DataFrame([[word]], columns=df.columns)\n",
    "        df = pd.concat([new_row, df], ignore_index=True)\n",
    "        df.columns = new_columns_name\n",
    "        df.fillna(\"dummy\", inplace=True)\n",
    "\n",
    "    elif N_columns == 2:\n",
    "        print(about, \"has 2 columns\")\n",
    "        dummy_row = pd.DataFrame([[' ', 'dummy']], columns=df.columns)\n",
    "        word = df.columns.to_list()[0]\n",
    "        pos_tag = df.columns.to_list()[1]\n",
    "        new_row = pd.DataFrame([[word, pos_tag]], columns=df.columns)\n",
    "        df = pd.concat([dummy_row, new_row, df], ignore_index=True)\n",
    "        df.columns = new_columns_name\n",
    "        df.fillna(\"dummy\", inplace=True)\n",
    "        \n",
    "    else:\n",
    "        print(\" --- Invalid number of columns ---\")\n",
    "\n",
    "    print(\"Update complete\\n\")    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data has 2 columns\n",
      "Update complete\n",
      "\n",
      "Dev data has 2 columns\n",
      "Update complete\n",
      "\n",
      "Test data has 1 column\n",
      "Update complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('data/', 'train')\n",
    "dev_df = load_data('data/', 'dev')\n",
    "test_df = load_data('data/', 'test')\n",
    "\n",
    "two_columns_name = ['Word', 'POS Tag']\n",
    "one_columns_name = ['Word']\n",
    "\n",
    "updated_train_df = update_df_columns(train_df, two_columns_name, \"Train data\")\n",
    "updated_dev_df = update_df_columns(dev_df, two_columns_name, \"Dev data\")\n",
    "updated_test_df = update_df_columns(test_df, one_columns_name, \"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_train_df.head(33)\n",
    "# updated_train_df.tail(5)\n",
    "# updated_train_df\n",
    "\n",
    "# updated_train_df[updated_train_df['POS Tag'] == \"dummy\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of Tasks\n",
    "\n",
    "1. Vocabulary Creation\n",
    "2. Model Learning\n",
    "3. Greedy Decoding with HMM\n",
    "4. Viterbi Decoding with HMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vocabulary Creation\n",
    "\n",
    "- **Problem:** Creating vocabulary to handle unkown words.\n",
    "    - **Solution:** Replace rare words wtih whose occurrences are less than a threshold (ie: 3) with a special token `< unk >`\n",
    "\n",
    "---\n",
    "\n",
    "1. [ ] Create a vocabulary using the training data in the file train\n",
    "2. [ ] Output the vocabulary into a txt file named `vocab.txt`\n",
    "    - [ ] See PDF on how to properly format vocabulary file\n",
    "3. [ ] Questions\n",
    "    1. [ ] What is the selected threshold for unknown words replacement?\n",
    "    2. [ ] What is the total size of your vocabulary?\n",
    "    3. [ ] What is the total occurrences of the special token `< unk >`after replacement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siddhant\n",
    "# shivam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\n",
      ",           46476\n",
      "the         39533\n",
      "dummy       38234\n",
      ".           37452\n",
      "of          22104\n",
      "            ...  \n",
      "Birthday        1\n",
      "Happy           1\n",
      "Bertie          1\n",
      "crouched        1\n",
      "Huricane        1\n",
      "Name: count, Length: 43193, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "true_false_series = updated_train_df['Word'].value_counts()\n",
    "print(true_false_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame(true_false_series)\n",
    "vocab_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_15609/3980822034.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  updated_false_vocab_df['Word'] = ' <unk> '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>29443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy</td>\n",
       "      <td>3</td>\n",
       "      <td>38234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>trafficking</td>\n",
       "      <td>13746</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>7.62</td>\n",
       "      <td>13747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>gut</td>\n",
       "      <td>13748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13749</th>\n",
       "      <td>17.3</td>\n",
       "      <td>13749</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>seminar</td>\n",
       "      <td>13750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  index  count\n",
       "0            <unk>      0  29443\n",
       "1                ,      1  46476\n",
       "2              the      2  39533\n",
       "3            dummy      3  38234\n",
       "4                .      4  37452\n",
       "...            ...    ...    ...\n",
       "13746  trafficking  13746      4\n",
       "13747         7.62  13747      4\n",
       "13748          gut  13748      4\n",
       "13749         17.3  13749      4\n",
       "13750      seminar  13750      4\n",
       "\n",
       "[13751 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_false_series = vocab_df['count'] > 3\n",
    "\n",
    "updated_vocab_df = vocab_df.loc[true_false_series == True]\n",
    "updated_false_vocab_df = vocab_df.loc[true_false_series == False]\n",
    "updated_false_vocab_df['Word'] = ' <unk> '\n",
    "print()\n",
    "N_updated_false_vocab_df = len(updated_false_vocab_df)\n",
    "N_updated_false_vocab_df\n",
    "new_row = pd.DataFrame([['<unk>', N_updated_false_vocab_df]], columns=updated_vocab_df.columns)\n",
    "\n",
    "df = pd.concat([new_row, updated_vocab_df], ignore_index=True)\n",
    "N_vocab = range(0, len(updated_vocab_df)+1)\n",
    "\n",
    "df['index'] = N_vocab\n",
    "\n",
    "df = df.reindex(columns=['Word', 'index', 'count'])\n",
    "df\n",
    "# df.to_csv('vocab.txt', header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>29443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>46476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy</td>\n",
       "      <td>3</td>\n",
       "      <td>38234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>4</td>\n",
       "      <td>37452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13746</th>\n",
       "      <td>trafficking</td>\n",
       "      <td>13746</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13747</th>\n",
       "      <td>7.62</td>\n",
       "      <td>13747</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13748</th>\n",
       "      <td>gut</td>\n",
       "      <td>13748</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13749</th>\n",
       "      <td>17.3</td>\n",
       "      <td>13749</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>seminar</td>\n",
       "      <td>13750</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13751 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  index  count\n",
       "0            <unk>      0  29443\n",
       "1                ,      1  46476\n",
       "2              the      2  39533\n",
       "3            dummy      3  38234\n",
       "4                .      4  37452\n",
       "...            ...    ...    ...\n",
       "13746  trafficking  13746      4\n",
       "13747         7.62  13747      4\n",
       "13748          gut  13748      4\n",
       "13749         17.3  13749      4\n",
       "13750      seminar  13750      4\n",
       "\n",
       "[13751 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Learning\n",
    "\n",
    "- Learn an HMM from the training data\n",
    "- **HMM Parameters:**\n",
    "  <div style=\"text-align: center;\">\n",
    "\n",
    "    $\n",
    "    \\text{Transition Probability (} t \\text{)}: \\quad t(s' \\mid s) = \\frac{\\text{count}(s \\rightarrow s')}{\\text{count}(s)}\n",
    "    $\n",
    "\n",
    "    $\n",
    "    \\text{Emission Probability (} e \\text{)}: \\quad e(x \\mid s) = \\frac{\\text{count}(s \\rightarrow x)}{\\text{count}(s)}\n",
    "    $\n",
    "\n",
    "  </div>\n",
    "\n",
    "---\n",
    "\n",
    "1. [x] Learn a model using the training data in the file train\n",
    "2. [ ] Output the learned model into a model file in json format, named `hmm.json`. The model file should contains two dictionaries for the emission and transition parameters, respectively.\n",
    "    1. [ ] 1st dictionary: Named transition, contains items with pairs of (s, s′) as key and t(s′|s) as value. \n",
    "    2. [ ] 2nd dictionary: Named emission, contains items with pairs of (s, x) as key and e(x|s) as value.\n",
    "3. Question\n",
    "    1. [ ] How many transition and emission parameters in your HMM?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>dummy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pierre</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vinken</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950308</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950309</th>\n",
       "      <td>San</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950310</th>\n",
       "      <td>Francisco</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950311</th>\n",
       "      <td>instead</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950312</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word POS Tag\n",
       "0                   dummy\n",
       "1          Pierre     NNP\n",
       "2          Vinken     NNP\n",
       "3               ,       ,\n",
       "4              61      CD\n",
       "...           ...     ...\n",
       "950308         to      TO\n",
       "950309        San     NNP\n",
       "950310  Francisco     NNP\n",
       "950311    instead      RB\n",
       "950312          .       .\n",
       "\n",
       "[950313 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_train_df.head(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifts(states_series: pd.Series, current_state: int, next_state: int):\n",
    "    \"\"\"Splits a given create_shifts into multiple input rows where each input row has a s' and s\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    Return:\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(states_series)\n",
    "    # print(df)\n",
    "    cols = list()\n",
    "    \n",
    "    lag_col_names = []\n",
    "    count_lag = 0\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for prior_observation in range(current_state, 0, -1):\n",
    "        # print(\"prior_observation: \", prior_observation)\n",
    "        cols.append(df.shift(prior_observation))\n",
    "        new_col_name = \"given_state\"\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, next_state):\n",
    "        cols.append(df.shift(-i))\n",
    "        new_col_name = \"find_state\"\n",
    "        # print(new_col_name)\n",
    "        lag_col_names.append(new_col_name)\n",
    "        \n",
    "        # put it all together\n",
    "        uts_sml_df = pd.concat(cols, axis=1) \n",
    "        uts_sml_df.columns=[lag_col_names]\n",
    "        # drop rows with NaN values\n",
    "        uts_sml_df.dropna(inplace=True)\n",
    "        \n",
    "    return uts_sml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>given_state</th>\n",
       "      <th>find_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummy</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNP</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CD</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950308</th>\n",
       "      <td>PRP</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950309</th>\n",
       "      <td>TO</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950310</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950311</th>\n",
       "      <td>NNP</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950312</th>\n",
       "      <td>RB</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       given_state find_state\n",
       "1            dummy        NNP\n",
       "2              NNP        NNP\n",
       "3              NNP          ,\n",
       "4                ,         CD\n",
       "5               CD        NNS\n",
       "...            ...        ...\n",
       "950308         PRP         TO\n",
       "950309          TO        NNP\n",
       "950310         NNP        NNP\n",
       "950311         NNP         RB\n",
       "950312          RB          .\n",
       "\n",
       "[950312 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_series = updated_train_df['POS Tag']\n",
    "states_df = create_shifts(states_series, 1, 1)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states_df = create_shifts(updated_train_df, ', 1, 1)\n",
    "# states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_on_s(df, pos_tag):\n",
    "    # print(\"Given\", pos_tag)\n",
    "    given_filter = (df['given_state'] == pos_tag)\n",
    "    condition_on_given = df[given_filter]\n",
    "    condition_on_given.dropna(how='all', inplace=True)\n",
    "    given_df = condition_on_given['given_state']\n",
    "\n",
    "    return given_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_on_s_prime(df, pos_tag):\n",
    "    # print(\"Find\", pos)\n",
    "    find_filter = (df['find_state'] == pos_tag)\n",
    "    condition_on_find = df[find_filter]\n",
    "    condition_on_find.dropna(how='all', inplace=True)\n",
    "    find_df = condition_on_find['find_state']\n",
    "    \n",
    "    return find_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>given_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950297</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950302</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950303</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950310</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950311</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87608 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       given_state\n",
       "2              NNP\n",
       "3              NNP\n",
       "17             NNP\n",
       "21             NNP\n",
       "22             NNP\n",
       "...            ...\n",
       "950297         NNP\n",
       "950302         NNP\n",
       "950303         NNP\n",
       "950310         NNP\n",
       "950311         NNP\n",
       "\n",
       "[87608 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df = condition_on_s(states_df, 'NNP')\n",
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>find_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950296</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950301</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950302</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950309</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950310</th>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87608 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       find_state\n",
       "1             NNP\n",
       "2             NNP\n",
       "16            NNP\n",
       "20            NNP\n",
       "21            NNP\n",
       "...           ...\n",
       "950296        NNP\n",
       "950301        NNP\n",
       "950302        NNP\n",
       "950309        NNP\n",
       "950310        NNP\n",
       "\n",
       "[87608 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_prime_df = condition_on_s_prime(states_df, 'NNP')\n",
    "s_prime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Add condition to check all elements in specific column should be that POS Tag and NOT another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_elements(s_df, s_prime_df):\n",
    "    \"\"\"Merge s and s' across same index\"\"\"\n",
    "    df = pd.merge(s_df, s_prime_df, left_index=True, right_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>given_state</th>\n",
       "      <th>find_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950270</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950271</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950296</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950302</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950310</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33139 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       given_state find_state\n",
       "2              NNP        NNP\n",
       "21             NNP        NNP\n",
       "26             NNP        NNP\n",
       "35             NNP        NNP\n",
       "45             NNP        NNP\n",
       "...            ...        ...\n",
       "950270         NNP        NNP\n",
       "950271         NNP        NNP\n",
       "950296         NNP        NNP\n",
       "950302         NNP        NNP\n",
       "950310         NNP        NNP\n",
       "\n",
       "[33139 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = get_common_elements(s_df, s_prime_df)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probability(word_pos_tag_df, col_name, merged_df, pos_tag, s_prime_pos_tag):\n",
    "    \"\"\"Calculate\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    word_pos_tag_df: `pd.DataFrame`\n",
    "        The updated DF of either train (N x 2: Word and POS Tag), dev (N x 2: Word and POS Tag), or test (N x 1: POS Tag).\n",
    "\n",
    "    col_name: `str`\n",
    "        Column name of word_pos_tag_df to get. Should only be POS Tag. If Word column, then throw error.\n",
    "        \n",
    "    merged_df: `pd.DataFrame`\n",
    "        The subset DF that reps the all matchings of s (given) and s' (find).\n",
    "\n",
    "    pos_tag: `str`\n",
    "        The POS Tag of interests to find the total\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    t_prob: `float` \n",
    "        The probability of t\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    N_pos_tag_each_series = word_pos_tag_df[col_name].value_counts()\n",
    "    # print(\"Each POS Tag has N values: \\n\", N_pos_tag_each_series)\n",
    "\n",
    "    s = N_pos_tag_each_series.to_dict()[pos_tag]\n",
    "    # print(f\"s (given) = {pos_tag} with length of: {s}\")\n",
    "    \n",
    "    # s = states_df.value_counts().to_dict()[pos_tag]\n",
    "    # print(f\"Length of given: {s}\")\n",
    "\n",
    "    s_prime = len(merged_df)\n",
    "    # print(f\"s' (find) = {s_prime_pos_tag} with length of: {s_prime}\")\n",
    "\n",
    "    t = s_prime / s\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3782645420509543"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_probability(updated_train_df, 'POS Tag', merged_df, 'NNP', 'NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probability_per_sentence(word_pos_tag_df, df, col_name):\n",
    "\n",
    "    # probs = []\n",
    "    prob_dict  = {}\n",
    "    # Iterate over the rows of df\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        # print(\"index\",index)\n",
    "        # print(\"row\",row)\n",
    "\n",
    "            # Get values from column 1 and column 2\n",
    "        s_pos_tag = row['given_state']\n",
    "        s_prime_pos_tag = row['find_state']\n",
    "        \n",
    "        # print(f\"Row {index}: Given s = {given_s}, Find s' = {find_s_prime}\")\n",
    "        # print(f\"Row {index}: Pr({s_prime_pos_tag} | {s_pos_tag})\")\n",
    "        # print()\n",
    "\n",
    "        s_df = condition_on_s(df, s_pos_tag)\n",
    "        s_prime_df = condition_on_s_prime(df, s_prime_pos_tag)\n",
    "        merged_df = get_common_elements(s_df, s_prime_df)\n",
    "        prob = calc_probability(word_pos_tag_df, 'POS Tag', merged_df, s_pos_tag, s_prime_pos_tag)\n",
    "        # probs.append(prob)\n",
    "        # (\"JJ, LL\") = t\n",
    "        dict_key = s_prime_pos_tag + \", \" + s_pos_tag\n",
    "        prob_dict[dict_key] = prob\n",
    "            \n",
    "        # print(f\"Row {index}: Pr(s' = {s_prime_pos_tag} | s = {s_pos_tag}) --- {col_name} = {prob} \")\n",
    "        # print()\n",
    "        # print( prob_dict)\n",
    "    \n",
    " \n",
    "\n",
    "    # print(probs)\n",
    "    # if col_name == 'T':\n",
    "    #     update_col_name = col_name + ' probs'\n",
    "    # elif col_name == 'E':\n",
    "    #     update_col_name = col_name + ' probs'\n",
    "    # else: \n",
    "    #     print(\"Improper column name\")\n",
    "\n",
    "    # probs_series = pd.Series(probs)\n",
    "    # final_df = merged_df.join([probs_series], how)\n",
    "\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4940/950312 [35:31<113:17:10,  2.32it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t_values \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_probability_per_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdated_train_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 21\u001b[0m, in \u001b[0;36mcalc_probability_per_sentence\u001b[0;34m(word_pos_tag_df, df, col_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m s_prime_df \u001b[38;5;241m=\u001b[39m condition_on_s_prime(df, s_prime_pos_tag)\n\u001b[1;32m     20\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m get_common_elements(s_df, s_prime_df)\n\u001b[0;32m---> 21\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_pos_tag_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOS Tag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_pos_tag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_prime_pos_tag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# probs.append(prob)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# (\"JJ, LL\") = t\u001b[39;00m\n\u001b[1;32m     24\u001b[0m dict_key \u001b[38;5;241m=\u001b[39m s_prime_pos_tag \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m s_pos_tag\n",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m, in \u001b[0;36mcalc_probability\u001b[0;34m(word_pos_tag_df, col_name, merged_df, pos_tag, s_prime_pos_tag)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_probability\u001b[39m(word_pos_tag_df, col_name, merged_df, pos_tag, s_prime_pos_tag):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     N_pos_tag_each_series \u001b[38;5;241m=\u001b[39m \u001b[43mword_pos_tag_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# print(\"Each POS Tag has N values: \\n\", N_pos_tag_each_series)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     s \u001b[38;5;241m=\u001b[39m N_pos_tag_each_series\u001b[38;5;241m.\u001b[39mto_dict()[pos_tag]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/base.py:1010\u001b[0m, in \u001b[0;36mIndexOpsMixin.value_counts\u001b[0;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalue_counts\u001b[39m(\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    930\u001b[0m     dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    931\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m    932\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m    Return a Series containing counts of unique values.\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    Name: count, dtype: int64\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_counts_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/algorithms.py:927\u001b[0m, in \u001b[0;36mvalue_counts_internal\u001b[0;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_arraylike(values, func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 927\u001b[0m     keys, counts, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_counts_arraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m    929\u001b[0m         keys \u001b[38;5;241m=\u001b[39m keys\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/algorithms.py:981\u001b[0m, in \u001b[0;36mvalue_counts_arraylike\u001b[0;34m(values, dropna, mask)\u001b[0m\n\u001b[1;32m    978\u001b[0m original \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m    979\u001b[0m values \u001b[38;5;241m=\u001b[39m _ensure_data(values)\n\u001b[0;32m--> 981\u001b[0m keys, counts, na_counter \u001b[38;5;241m=\u001b[39m \u001b[43mhtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(original\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# datetime, timedelta, or period\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropna:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_values = calc_probability_per_sentence(updated_train_df, states_df, 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df = updated_train_df.loc[0:, ['POS Tag', 'Word']]\n",
    "emissions_df.rename(columns={'POS Tag': 'given_state', 'Word': 'find_state'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "e_values = calc_probability_per_sentence(updated_train_df, emissions_df[:21], 'E')\n",
    "e_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greedy Decoding with HMM\n",
    "\n",
    "1. [ ] Implement the greedy decoding algorithm\n",
    "2. [ ] Evaluate it on the development data\n",
    "3. [ ] Predicting the POS Tags of the sentences in the test data\n",
    "4. [ ] Output the predictions in a file named `greedy.out`, in the same format of training data\n",
    "5. [ ] Evaluate the results of the model on `eval.py` in the terminal with `python eval.py − p {predicted file} − g {gold-standard file}`\n",
    "6. [ ] Question\n",
    "    1. [ ] What is the accuracy on the dev data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calc_greedy(t, e):\n",
    "    g_values = np.multiply(t, e)\n",
    "    return np.max(g_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_greedy(t_values, e_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Viterbi Decoding with HMM\n",
    "\n",
    "1. [ ] Implement the viterbi decoding algorithm\n",
    "2. [ ] Evaluate it on the development data\n",
    "3. [ ] Predict the POS Tags of the sentences in the test data\n",
    "4. [ ] Output the predictions in a file named `viterbi.out`, in the same format of training data\n",
    "5. [ ] Question\n",
    "    1. [ ] What is the accuracy on the dev data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
