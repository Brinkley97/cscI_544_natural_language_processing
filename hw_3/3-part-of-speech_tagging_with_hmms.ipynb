{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3-Part-of-Speech Tagging with HMMs + Decoding Techniques (Greedy and Viterbi)\n",
    "\n",
    "- Detravious Jamari Brinkley\n",
    "- CSCI-544: Applied Natural Language Processing\n",
    "- python version: 3.11.4\n",
    "\n",
    "---\n",
    "\n",
    "1. Part-of-Speech (POS) Tagging [a type of sequence labelling task where of a given word, assign the part of speech]\n",
    "2. HMMs (Hidden Markov Model) [a generative-based model that's used for POS Tagging]\n",
    "    1. Generative-based [provides the probabilities for all possible combinations of values of variables in the set using the joint distribution]\n",
    "    2. With POS Tagging: Given a sequence of observations (sentences), the task is to infer the most likely sequence of hidden states (POS Tags) that could have generated the observed data.\n",
    "3. Decoding Techniques:\n",
    "    1. Greedy [find the optimal (OPT) solution at each step]\n",
    "    2. Viterbi [make use of dynammic programming to find the OPT solution within the entire search space]\n",
    "4. Notes of the data and given files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of Tasks\n",
    "\n",
    "1. Vocabulary Creation\n",
    "2. Model Learning\n",
    "3. Greedy Decoding with HMM\n",
    "4. Viterbi Decoding with HMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Vocabulary Creation\n",
    "\n",
    "- **Problem:** Creating vocabulary to handle unkown words.\n",
    "    - **Solution:** Replace rare words wtih whose occurrences are less than a threshold (ie: 3) with a special token `< unk >`\n",
    "\n",
    "---\n",
    "\n",
    "1. [ ] Create a vocabulary using the training data in the file train\n",
    "2. [ ] Output the vocabulary into a txt file named `vocab.txt`\n",
    "    - [ ] See PDF on how to properly format vocabulary file\n",
    "3. [ ] Questions\n",
    "    1. [ ] What is the selected threshold for unknown words replacement?\n",
    "    2. [ ] What is the total size of your vocabulary?\n",
    "    3. [ ] What is the total occurrences of the special token `< unk >`after replacement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Learning\n",
    "\n",
    "- Learn an HMM from the training data\n",
    "- **HMM Parameters:**\n",
    "  <div style=\"text-align: center;\">\n",
    "\n",
    "    $\n",
    "    \\text{Transition Probability (} t \\text{)}: \\quad t(s' \\mid s) = \\frac{\\text{count}(s \\rightarrow s')}{\\text{count}(s)}\n",
    "    $\n",
    "\n",
    "    $\n",
    "    \\text{Emission Probability (} e \\text{)}: \\quad e(x \\mid s) = \\frac{\\text{count}(s \\rightarrow x)}{\\text{count}(s)}\n",
    "    $\n",
    "\n",
    "  </div>\n",
    "\n",
    "---\n",
    "\n",
    "1. [x] Learn a model using the training data in the file train\n",
    "2. [ ] Output the learned model into a model file in json format, named `hmm.json`. The model file should contains two dictionaries for the emission and transition parameters, respectively.\n",
    "    1. [ ] 1st dictionary: Named transition, contains items with pairs of (s, s′) as key and t(s′|s) as value. \n",
    "    2. [ ] 2nd dictionary: Named emission, contains items with pairs of (s, x) as key and e(x|s) as value.\n",
    "3. Question\n",
    "    1. [ ] How many transition and emission parameters in your HMM?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Greedy Decoding with HMM\n",
    "\n",
    "1. [ ] Implement the greedy decoding algorithm\n",
    "2. [ ] Evaluate it on the development data\n",
    "3. [ ] Predicting the POS Tags of the sentences in the test data\n",
    "4. [ ] Output the predictions in a file named `greedy.out`, in the same format of training data\n",
    "5. [ ] Evaluate the results of the model on `eval.py` in the terminal with `python eval.py − p {predicted file} − g {gold-standard file}`\n",
    "6. [ ] Question\n",
    "    1. [ ] What is the accuracy on the dev data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Viterbi Decoding with HMM\n",
    "\n",
    "1. [ ] Implement the viterbi decoding algorithm\n",
    "2. [ ] Evaluate it on the development data\n",
    "3. [ ] Predict the POS Tags of the sentences in the test data\n",
    "4. [ ] Output the predictions in a file named `viterbi.out`, in the same format of training data\n",
    "5. [ ] Question\n",
    "    1. [ ] What is the accuracy on the dev data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
