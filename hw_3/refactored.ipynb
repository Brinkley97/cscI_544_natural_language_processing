{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactored HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/zn5r8vq12nv5p23dtlr15sk40000gn/T/ipykernel_37757/2865552994.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_path = \"data/train\"\n",
    "df = pd.read_csv(file_path, sep = \"\\t\", header = None, names=['Index', 'Word', 'POS'], skip_blank_lines=False)\n",
    "\n",
    "# fill nan with dummy\n",
    "df['POS'] = df['POS'].fillna(\"dummy\") #on new lines change pos tag to dummy\n",
    "word_count = df['Word'].value_counts().to_dict()\n",
    "\n",
    "threshold = 3 \n",
    "words_greater_than_3 = {}\n",
    "words_greater_than_3[\"< unk >\"] = 0\n",
    "\n",
    "# removing words less than threshold and replacing with unk\n",
    "for word, freq in word_count.items():\n",
    "    if freq > threshold:\n",
    "        words_greater_than_3[word] = freq\n",
    "    else:\n",
    "        words_greater_than_3[\"< unk >\"] += 1\n",
    "\n",
    "df['Word'] = df['Word'].apply(lambda x: x if x in words_greater_than_3 else \"<unk>\")\n",
    "\n",
    "# create txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob = defaultdict(int)\n",
    "emission_prob = defaultdict(int)\n",
    "N_state = defaultdict(int)\n",
    " \n",
    "\n",
    "df['Previous_POS'] = df['POS'].shift(1) # previous state for trnasition probabilities\n",
    "\n",
    "# iterate through vocabulary\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "    emission_prob[(row[\"POS\"], row[\"Word\"])] += 1\n",
    "    # transition count + 1\n",
    "    if pd.notnull(row['Previous_POS']):  # Check if it's not NaN\n",
    "        transition_prob[(row[\"POS\"], row['Previous_POS'])] += 1\n",
    "\n",
    "    # state_count + 1; \n",
    "    N_state[(row[\"POS\"])] += 1\n",
    "\n",
    "# print(emission_prob)\n",
    "print(transition_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(transition_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities\n",
    "transition_probs = {} # dictionary definition\n",
    "for key,value in transition_prob.items(): # iterate through dicitionary \n",
    "\n",
    "    curr_state = key[0]\n",
    "    print('current state: ', curr_state, \"\\nKey: \", key)\n",
    "    print(\"Value of dictionary at the index: \", value,'\\nNumber of times this state has been the current state: ', N_state[curr_state])\n",
    "    transition_probs[key] = value / N_state[curr_state]\n",
    "    \n",
    "    # how many times you've seen the (s => s') = v / how many times you've seen the current state , s  \n",
    "    break \n",
    "print(transition_probs)\n",
    "\n",
    "# Calculate emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store t and e in dict and in json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
